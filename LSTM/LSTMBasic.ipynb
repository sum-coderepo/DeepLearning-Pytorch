{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhGAJfA2dV7YGWr7VeybNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sum-coderepo/DeepLearning-Pytorch/blob/master/LSTM/LSTMBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeqYF9g7_9O8"
      },
      "source": [
        "Taken From Here\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOg184l4_3_K"
      },
      "source": [
        "https://galhever.medium.com/sentiment-analysis-with-pytorch-part-4-lstm-bilstm-model-84447f6c4525"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI1JBX1uAHj6"
      },
      "source": [
        "The hidden state acts as the neural networks memory. It holds information on previous data the network has seen before.\n",
        "\n",
        "The operations on the information is controlled by three corresponding gates:\n",
        " \n",
        "\n",
        "*   Forget gate: Controls which content to keep and which should be forgotten from prior steps.\n",
        "*   Input Gate: Controls which information from the current step is relevant to add to the next steps.\n",
        "* Output Gate: Controls what should be the next hidden state, i.e. the output of the current step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXYYIE4kArf9"
      },
      "source": [
        "**What is BiLSTM Model?** </br></br>\n",
        "Bidirectional LSTM (BiLSTM) model maintains two separate states for forward and backward inputs that are generated by two different LSTMs. The first LSTM is a regular sequence that starts from the beginning of the sentence, while in the second LSTM, the input sequence are fed in the opposite order. The idea behind bi-directional network is to capture information of surrounding inputs. It usually learns faster than one-directional approach although it depends on the task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_56EeKtgA3_O"
      },
      "source": [
        "lr = 1e-4\n",
        "batch_size = 50\n",
        "dropout_keep_prob = 0.5\n",
        "embedding_size = 300\n",
        "max_document_length = 100  # each sentence has until 100 words\n",
        "dev_size = 0.8 # split percentage to train\\validation data\n",
        "max_size = 5000 # maximum vocabulary size\n",
        "seed = 1\n",
        "num_classes = 3\n",
        "num_hidden_nodes = 93\n",
        "hidden_dim2 = 128\n",
        "num_layers = 2  # LSTM layers\n",
        "bi_directional = False \n",
        "num_epochs = 7"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zKKQbuIA_ID"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, lstm_units, hidden_dim , num_classes, lstm_layers,\n",
        "                 bidirectional, dropout, pad_index, batch_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            lstm_units,\n",
        "                            num_layers=lstm_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        self.fc1 = nn.Linear(lstm_units * num_directions, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_directions = num_directions\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h, c = (Variable(torch.zeros(self.lstm_layers * self.num_directions, batch_size, self.lstm_units)),\n",
        "                Variable(torch.zeros(self.lstm_layers * self.num_directions, batch_size, self.lstm_units)))\n",
        "        return h, c\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        batch_size = text.shape[0]\n",
        "        h_0, c_0 = self.init_hidden(batch_size)\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        packed_embedded = pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
        "        output, (h_n, c_n) = self.lstm(packed_embedded, (h_0, c_0))\n",
        "        output_unpacked, output_lengths = pad_packed_sequence(output, batch_first=True)\n",
        "        out = output_unpacked[:, -1, :]\n",
        "        rel = self.relu(out)\n",
        "        dense1 = self.fc1(rel)\n",
        "        drop = self.dropout(dense1)\n",
        "        preds = self.fc2(drop)\n",
        "        return preds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ZKSJUJBLXT"
      },
      "source": [
        "The `pack_padded_sequence` is a format that enables the model to ignore the padded elements. LSTM model does not distinguish between padded elements and regular elements, but using this function it will not perform gradients calculation for backpropagation step for the padded values. When we feed the model with packed input it becomes dynamic and save unnecessary calculations. The pad_packed_sequence function is a reversed operation for `pack_padded_sequence` and will bring the output back to the familiar format `[batch_size, sentence_length, hidden_features].`\n",
        "</br>\n",
        "</br>\n",
        "\n",
        " **Init_hidden Function** </br>\n",
        "In the beginning we need to initialize the hidden states to zero and feed the LSTM layer with it so we can use a function that will do it for us for each batch separately.\n",
        "\n",
        "\n",
        " **LSTM Layer**</br>\n",
        "Pytorch’s nn.LSTM expects to a 3D-tensor as an input `[batch_size, sentence_length, embbeding_dim]`.</br>\n",
        "\n",
        "For each word in the sentence, each layer computes the input i, forget f and output o gate and the new cell content c’ (the new content that should be written to the cell). It will also compute the current cell state and the hidden state.\n",
        "\n",
        "\n",
        "\n",
        "**Parameters for LSTM Layer:**</br></br>\n",
        "**Input_size:** The number of features for each element in the input in our model. E.g., In our case each element (word) has 300 features that refer to the embedding_dim.</br></br>\n",
        "**Hidden_size:** This variable defines the number of LSTM hidden units.</br></br>\n",
        "**Num_layers:** This argument defines for multi-layer LSTMs the number of stacking LSTM layers in the model. In our case for example, we set this argument to lstm_layers=2 which means that the input x at time t of the second layer is the hidden state h at time t of the previous layer multiplied by dropout.</br></br>\n",
        "**Batch_first:** nn.LSTM layer expects the batch dimension in the input to be first as [batch_size, sentence_length, embbeding_dim] using the batch_first=TRUE it can be provided.</br></br>\n",
        "**Dropout:** If this argument will be greater than zero, it will produce Dropout layer with dropout probability on each output of the LSTM layer except the last one.</br></br>\n",
        "**Bidirectional:** By changing bidirectional variable modes we can control the model type (False= LSTM\\True= BiLSTM).</br></br>\n",
        "\n",
        "The inputs and output for the LSTM Layer can be explained by the diagram below (w represents the number of LSTM layers, in our case it’s equal to 2):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ys5Ws41GqMG"
      },
      "source": [
        "The input of the LSTM Layer:\n",
        "**Input:** In our case it’s a packed input but it can also be the original sequence while each Xi represents a word in the sentence (with padding elements).</br></br>\n",
        "**h_0:** The initial hidden state that we feed with the model.</br></br>\n",
        "**c_0:** The initial cell state that we feed with the model.</br></br>\n",
        "The output of the LSTM Layer:</br>\n",
        "**Output:** The first value returned by LSTM contains all the hidden states throughout the sequence.</br></br>\n",
        "**h_n:** The second output are the last hidden states of each of the LSTM layers.</br></br>\n",
        "**c_n:** The third output is the last cell state for each of the LSTM layers.</br></br>\n",
        "To get the hidden state of the last time step we used output_unpacked[:, -1, :] command and we use it to feed the next fully-connected layer.</br></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "GoZkqv1MEkC3",
        "outputId": "77bb9e83-c11c-40ca-9ca2-4cc65d589a57"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://miro.medium.com/max/640/0*UOHtKtIqmTTGdUm-.png\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/640/0*UOHtKtIqmTTGdUm-.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "javZUbuKI0cx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "path = 'C:/'\n",
        "path_data = os.path.join(path, \"data\")\n",
        "\n",
        "# parameters\n",
        "model_type = \"LSTM\"\n",
        "data_type = \"token\" # or: \"morph\"\n",
        "\n",
        "char_based = True\n",
        "if char_based:\n",
        "    tokenizer = lambda s: list(s) # char-based\n",
        "else:\n",
        "    tokenizer = lambda s: s.split() # word-based\n",
        "\n",
        "Text.build_vocab(train_data, max_size=max_size)\n",
        "Label.build_vocab(train_data)\n",
        "vocab_size = len(Text.vocab)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = create_iterator(train_data, valid_data, test_data, batch_size, device)\n",
        "\n",
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "lstm_model = LSTM(vocab_size, embedding_size, n_filters, filter_sizes, pool_size, hidden_size, num_classes, dropout_keep_prob)\n",
        "\n",
        "# optimization algorithm\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)\n",
        "# train and evaluation\n",
        "if (to_train):\n",
        "    # train and evaluation\n",
        "    run_train(num_epochs, lstm_model, train_iterator, valid_iterator, optimizer, loss_func, model_type)\n",
        "\n",
        "# load weights\n",
        "lstm_model.load_state_dict(torch.load(os.path.join(path, \"saved_weights_LSTM.pt\")))\n",
        "# predict\n",
        "test_loss, test_acc = evaluate(lstm_model, test_iterator, loss_func)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xetCbRR04iT9"
      },
      "source": [
        "The input of the nn.LSTM is \"input of shape (seq_len, batch, input_size)\" with \"input_size – The number of expected features in the input x\",\n",
        "\n",
        "And the output is: \"output of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the LSTM, for each t.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU8vBdi-4aMO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_size = 5\n",
        "hidden_size = 10\n",
        "num_layers = 1\n",
        "output_size = 1\n",
        "\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "X = [\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "    [[1,2,3,4,5]],\n",
        "]\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "print(X.shape)         # (seq_len, batch_size, input_size) = (7, 1, 5)\n",
        "out, hidden = lstm(X)  # Where X's shape is ([7,1,5])\n",
        "print(out.shape)       # (seq_len, batch_size, hidden_size) = (7, 1, 10)\n",
        "out = out[-1]          # Get output of last step\n",
        "print(out.shape)       # (batch, hidden_size) = (1, 10)\n",
        "out = fc(out)          # Push through linear layer\n",
        "print(out.shape)       # (batch_size, output_size) = (1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOqng1od5IPE"
      },
      "source": [
        " batch_size = 1 and output_size = 1\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGnfCTr8_yov"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}