{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "RNN (1) (1)",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 3824766781752871
    },
    "colab": {
      "name": "RNN (1) (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sum-coderepo/DeepLearning-Pytorch/blob/master/PytorchTutorials/NN_languageModel1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d72337f3-a1c0-4d5b-a146-8094ea8ce529"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu2DC1lWnsJo",
        "outputId": "f39e81cd-e598-4382-8408-6dfeab06e60b"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import string\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spacy.lang.en import English\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "#nlp.add_pipe('sentencizer')\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "nlp.max_length = 15000000"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "af5320bb-a885-4fb5-ae5d-5b05676f0a18"
        },
        "id": "aoiSuEsEnsJ3",
        "outputId": "8f413ab2-61a1-45f9-db1c-985aa4c5a7fc"
      },
      "source": [
        "#pip install --ignore-installed --upgrade tensorflow-gpu==2.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "744e3afc-dc1f-4086-a25b-925da829c487"
        },
        "id": "3qoHDvNpnsJ5"
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self):\n",
        "        self.dictionary = Dictionary()\n",
        "\n",
        "    def get_data(self, path, batch_size=20):\n",
        "        # Add words to the dictionary\n",
        "        split_sent = split_in_sentences1(path)\n",
        "        tokens = {1:0,2:0,3:0}\n",
        "        \n",
        "        train, test = train_test_split(split_sent, train_size = 0.7)\n",
        "        test , val = train_test_split(test, train_size = 0.66)        \n",
        "        print(len(train), len(test), len(val))\n",
        "        \n",
        "        lst = [train, test, val]\n",
        "        seq = 0\n",
        "        for data in lst:\n",
        "          seq = seq + 1\n",
        "          for line in data:\n",
        "            words = line.split() + ['<eos>']\n",
        "            tokens[seq] += len(words)\n",
        "            for word in words:\n",
        "                self.dictionary.add_word(word)\n",
        "                \n",
        "        \n",
        "        print(tokens)\n",
        "        train_ids = torch.LongTensor(tokens[1])\n",
        "        test_ids = torch.LongTensor(tokens[2])\n",
        "        val_ids = torch.LongTensor(tokens[3])\n",
        "             \n",
        "        train_tensor = self.create_tensors(train_ids, train)\n",
        "        test_tensor = self.create_tensors(test_ids, test)\n",
        "        val_tensor = self.create_tensors(val_ids, val)\n",
        "        \n",
        "        return train_tensor, test_tensor, val_tensor\n",
        "      \n",
        "      \n",
        "    def create_tensors( self, tensor, data):\n",
        "        token = 0\n",
        "        for line in data:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    tensor[token] = self.dictionary.word2idx[word]\n",
        "                    #print(word, self.dictionary.word2idx[word])\n",
        "                    token += 1\n",
        "        num_batches = tensor.size(0) // batch_size\n",
        "        tensor = tensor[:num_batches*batch_size]\n",
        "        return tensor.view(batch_size, -1)  \n",
        "      \n",
        "       \n",
        "def split_in_sentences1(path): \n",
        "    split_sent = []\n",
        "    with open(path, 'r') as f:\n",
        "      data = f.read()\n",
        "      data = data.split('\\n')\n",
        "      data = \" \".join(data) \n",
        "      data = data.split('.')\n",
        "      for sent in data:\n",
        "        if len(str(sent).strip())> 0:\n",
        "            split_sent.append(str(sent).strip())\n",
        "    return split_sent  \n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6e0cf949-8cd1-430a-968e-d83d7409bdd3"
        },
        "id": "_uTgFmN_nsJ8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "embed_size = 128\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "num_epochs = 10\n",
        "num_samples = 1000     # number of words to be sampled\n",
        "batch_size = 20 #5\n",
        "seq_length = 30 #5\n",
        "learning_rate = 0.002"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "0ad101b9-0d87-4041-bc86-72ea31db77be"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr_XdbCLnsJ-",
        "outputId": "e7509700-4302-40ec-d6a5-4e6d41a4b6dd"
      },
      "source": [
        "corpus = Corpus()\n",
        "train_tensors, test_tensors, val_tensors = corpus.get_data('brown_medium.txt', batch_size)\n",
        "vocab_size = len(corpus.dictionary)\n",
        "num_batches = train_tensors.size(1) // seq_length"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2536 717 370\n",
            "{1: 57947, 2: 16050, 3: 8457}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "da7384d0-bca6-403c-bad7-71760e8e5558"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-oMAvSBnsJ_",
        "outputId": "866ff591-849f-4118-dc0b-57de09f70903"
      },
      "source": [
        "train_tensors.size(), test_tensors.size(), val_tensors.size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 2897]), torch.Size([20, 802]), torch.Size([20, 422]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIm-iw1Zot5m",
        "outputId": "2582297e-0d8a-408f-9976-cffe36f83979"
      },
      "source": [
        "num_batches"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f44fead7-c4df-4140-94ed-49343a931f6a"
        },
        "id": "7lm3Yrr0nsKG"
      },
      "source": [
        "# RNN based language model\n",
        "class RNNLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(RNNLM, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        \n",
        "    def forward(self, x, h):\n",
        "        # Embed word ids to vectors\n",
        "        x = self.embed(x)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, (h, c) = self.lstm(x, h)\n",
        "        \n",
        "        # Reshape output to (batch_size*sequence_length, hidden_size)\n",
        "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
        "        \n",
        "        # Decode hidden states of all time steps\n",
        "        out = self.linear(out)\n",
        "        return out, (h, c)\n",
        "      \n",
        "    \n",
        "    def init_hidden(self,batch_size):\n",
        "        self.hidden = Variable(T.zeros(self.n_layers, batch_size, self.hidden_size).cuda())\n",
        "\n",
        "\n",
        "model = RNNLM(vocab_size, embed_size, hidden_size, num_layers).to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8af0f87c-8a8c-4c78-a6e5-737279058914"
        },
        "id": "KOFyvLDinsKH"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Truncated backpropagation\n",
        "def detach(states):\n",
        "    return [state.detach() for state in states] "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6be6bbfc-e52e-4c5d-beeb-2eb8677490ce"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJi4VhcDnsKI",
        "outputId": "7786da11-d0b7-48bd-874f-4cec9d9bc0de"
      },
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    states = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
        "              torch.zeros(num_layers, batch_size, hidden_size).to(device))\n",
        "    \n",
        "    for i in range(0, train_tensors.size(1) - seq_length, seq_length): \n",
        "        # Get mini-batch inputs and targets\n",
        "        inputs = train_tensors[:, i:i+seq_length].to(device)\n",
        "        targets = train_tensors[:, (i+1):(i+1)+seq_length].to(device)\n",
        "        states = detach(states)\n",
        "        outputs, states = model(inputs, states)\n",
        "        \n",
        "        loss = criterion(outputs, targets.reshape(-1))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        \n",
        "        step = (i+1) // seq_length\n",
        "        if step % 25 == 0:\n",
        "            print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
        "                   .format(epoch+1, num_epochs, step, num_batches, loss.item(), np.exp(loss.item())))\n",
        "      \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step[0/96], Loss: 9.7366, Perplexity: 16926.01\n",
            "Epoch [1/10], Step[25/96], Loss: 7.6375, Perplexity: 2074.49\n",
            "Epoch [1/10], Step[50/96], Loss: 7.6334, Perplexity: 2065.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "5e17d8ec-24ef-4a26-bf89-885126b57f11"
        },
        "id": "Mi2IPQsYnsKL",
        "outputId": "e2598c7d-d288-41c4-cae1-0ba64333ea86"
      },
      "source": [
        "model.parameters, model.eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">Out[71]: (&lt;bound method Module.parameters of RNNLM(\n",
              "   (embed): Embedding(88799, 128)\n",
              "   (lstm): LSTM(128, 1024, batch_first=True)\n",
              "   (linear): Linear(in_features=1024, out_features=88799, bias=True)\n",
              " )&gt;,\n",
              " &lt;bound method Module.eval of RNNLM(\n",
              "   (embed): Embedding(88799, 128)\n",
              "   (lstm): LSTM(128, 1024, batch_first=True)\n",
              "   (linear): Linear(in_features=1024, out_features=88799, bias=True)\n",
              " )&gt;)</div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[71]: (&lt;bound method Module.parameters of RNNLM(\n   (embed): Embedding(88799, 128)\n   (lstm): LSTM(128, 1024, batch_first=True)\n   (linear): Linear(in_features=1024, out_features=88799, bias=True)\n )&gt;,\n &lt;bound method Module.eval of RNNLM(\n   (embed): Embedding(88799, 128)\n   (lstm): LSTM(128, 1024, batch_first=True)\n   (linear): Linear(in_features=1024, out_features=88799, bias=True)\n )&gt;)</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "feff4feb-7990-4311-a5e4-75ca5a190c8b"
        },
        "id": "lJmGn92mnsKM",
        "outputId": "ba1fb138-ba8b-4c54-e853-9d6c1baf6afd"
      },
      "source": [
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = state = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
        "                 torch.zeros(num_layers, batch_size, hidden_size).to(device))\n",
        "    for i in range(0, data_source.size(0) - 1, seq_length):\n",
        "        data = data_source[:, i:i+seq_length].to(device)\n",
        "        targets = data_source[:, (i+1):(i+1)+seq_length].to(device)\n",
        "        output, hidden = model(data, hidden)\n",
        "        print(output.size())\n",
        "        output_flat = output.view(-1, ntokens)\n",
        "        print(output_flat.size(), targets.size())\n",
        "        total_loss += len(data) * criterion(output_flat, targets.reshape(-1)).data\n",
        "        print(total_loss)\n",
        "        hidden = detach(states)\n",
        "        \n",
        "    return total_loss.item()/ len(data_source)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b79e2be7-42e0-4cab-8c66-b0a9b7ffc148"
        },
        "id": "qUcX83q_nsKO",
        "outputId": "fcb8368a-9d4f-4899-b73d-d448192ebad2"
      },
      "source": [
        "# Run on test data.\n",
        "test_loss = evaluate(test_tensors)\n",
        "print('=' * 89)\n",
        "print('loss {:5.2f} | perplexity {:8.2f}'.format(test_loss, np.exp(test_loss)))\n",
        "print('=' * 89)\n",
        "#loss.item(), ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">torch.Size([600, 88799])\n",
              "torch.Size([600, 88799]) torch.Size([20, 30])\n",
              "tensor(195.0675)\n",
              "=========================================================================================\n",
              "loss  9.75 | perplexity 17212.23\n",
              "=========================================================================================\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">torch.Size([600, 88799])\ntorch.Size([600, 88799]) torch.Size([20, 30])\ntensor(195.0675)\n=========================================================================================\nloss  9.75 | perplexity 17212.23\n=========================================================================================\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "afff6962-8e7c-4ca9-bc65-ea523b02fd63"
        },
        "id": "DV66lRmznsKP",
        "outputId": "5edeab1c-9560-4d44-8be3-2f0fe43fc60e"
      },
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    }
  ]
}